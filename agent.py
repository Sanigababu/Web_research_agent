from search_tool import search_web
from scraper import extract_text
from summarizer import summarize_with_gemini

def run_agent(query):
    log = []  # Reasoning log
    report = f"# ğŸ§  Answer to: **{query}**\n\n"
    
    log.append(f"ğŸ“© Received query: '{query}'")
    log.append("ğŸ” Performing web search...")

    results = search_web(query)
    log.append(f"ğŸ”— Found {len(results)} results.")

    if not results:
        log.append("âŒ No results found. Stopping.")
        return "\n".join(log) + "\n\nNo useful results found."

    for idx, (title, url) in enumerate(results, 1):
        log.append(f"\n---\nğŸ”¸ Result {idx}: {title} ({url})")
        log.append("â†’ Attempting to extract content...")
        text = extract_text(url)

        if "Error" not in text and text.strip():
            log.append("âœ… Content extracted successfully.")
            log.append("â†’ Summarizing content using Gemini...")
            summary = summarize_with_gemini(text, query, url)
            log.append("âœ… Summary generated.")

            report += f"## {idx}. {title}\n"
            report += f"[ğŸ”— Source]({url})\n\n"
            report += f"**Summary:**\n{summary.strip()}\n\n"
        else:
            log.append("âš ï¸ Skipping â€” extraction failed or content empty.")

    if "##" not in report:
        log.append("âš ï¸ No valid content was found from any sources.")
        return "\n".join(log) + "\n\nNo useful content could be retrieved."

    log.append("\nâœ… Finished processing all results.")
    return "\n".join(log) + "\n\n---\n\n" + report

